{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_performer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41EWXAeL2nYs",
        "outputId": "92d03002-5572-4500-9646-a4d122b03fb2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install drive/MyDrive/lmd_transformer/pytorch_fast_transformers-0.3.0-cp36-cp36m-linux_x86_64.whl\n",
        "!pip install performer-pytorch --upgrade\n",
        "!pip install deepspeed\n",
        "!pip install pytorch-extension\n",
        "!pip install allennlp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Processing ./drive/MyDrive/lmd_transformer/pytorch_fast_transformers-0.3.0-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-fast-transformers==0.3.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->pytorch-fast-transformers==0.3.0) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->pytorch-fast-transformers==0.3.0) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->pytorch-fast-transformers==0.3.0) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->pytorch-fast-transformers==0.3.0) (3.7.4.3)\n",
            "Installing collected packages: pytorch-fast-transformers\n",
            "Successfully installed pytorch-fast-transformers-0.3.0\n",
            "Collecting performer-pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/73/ee/5a85abac769cfc6565e40be19fddc8cecf97af96c3739c258c2df5160276/performer_pytorch-0.14.1-py3-none-any.whl\n",
            "Collecting einops>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/a0/9935e030634bf60ecd572c775f64ace82ceddf2f504a5fd3902438f07090/einops-0.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: pytorch-fast-transformers>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from performer-pytorch) (0.3.0)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6 in /usr/local/lib/python3.6/dist-packages (from performer-pytorch) (1.7.0+cu101)\n",
            "Collecting local-attention>=1.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/47/34/21b2a040344a3a785ecee3c268ded02ceb9f8f4a636f20be7729204610a3/local_attention-1.1.1-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.6->performer-pytorch) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.6->performer-pytorch) (0.8)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6->performer-pytorch) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6->performer-pytorch) (0.16.0)\n",
            "Installing collected packages: einops, local-attention, performer-pytorch\n",
            "Successfully installed einops-0.3.0 local-attention-1.1.1 performer-pytorch-0.14.1\n",
            "Collecting deepspeed\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/f7/e45734d0074336e16f704372c85be7fa867abaa6f5667ffadbadb6ab4fa0/deepspeed-0.3.8.tar.gz (259kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 14.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from deepspeed) (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from deepspeed) (0.8.1+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from deepspeed) (4.41.1)\n",
            "Collecting tensorboardX==1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/12/dcaf67e1312475b26db9e45e7bb6f32b540671a9ee120b3a72d9e09bc517/tensorboardX-1.8-py2.py3-none-any.whl (216kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 34.6MB/s \n",
            "\u001b[?25hCollecting ninja\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/de/393468f2a37fc2c1dc3a06afc37775e27fde2d16845424141d4da62c686d/ninja-1.10.0.post2-py3-none-manylinux1_x86_64.whl (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 46.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->deepspeed) (1.18.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->deepspeed) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->deepspeed) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->deepspeed) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.4.0->deepspeed) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.8->deepspeed) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.8->deepspeed) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX==1.8->deepspeed) (50.3.2)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.3.8-cp36-none-any.whl size=255692 sha256=0ff24b0d5317aebd2f9241df3498211df8cb6667f922278a63243036f3c0361a\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/8f/5c/22efd14b664ffaebfb35e6d700641e8efab7d19e611242da40\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: tensorboardX, ninja, deepspeed\n",
            "Successfully installed deepspeed-0.3.8 ninja-1.10.0.post2 tensorboardX-1.8\n",
            "Collecting pytorch-extension\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/2e9110532020880d9ba06085c4b9a163fa8d8993d964bf61aeb217b7896b/pytorch_extension-0.1-py3-none-any.whl (156kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 16.9MB/s \n",
            "\u001b[?25hInstalling collected packages: pytorch-extension\n",
            "Successfully installed pytorch-extension-0.1\n",
            "Collecting allennlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/42/ee4abac910d0becba85ef0c2cfa2d5a954d986a1356708db5a0cd911783c/allennlp-1.2.2-py3-none-any.whl (505kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 15.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.12)\n",
            "Collecting overrides==3.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.8)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.8)\n",
            "Collecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/d5/1cc282dc23346a43aab461bf2e8c36593aacd34242bee1a13fa750db0cfe/jsonpickle-1.4.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torch<1.8.0,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.18.5)\n",
            "Collecting boto3<2.0,>=1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/3e/3a4546165383a5fc9f6f7ba15a261c768aee10662bb06105100d859e8940/boto3-1.16.35-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 53.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.23.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.41.1)\n",
            "Requirement already satisfied: spacy<2.4,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.2.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.1)\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/40/6f16e5ac994b16fa71c24310f97174ce07d3a97b433275589265c6b94d2b/jsonnet-0.17.0.tar.gz (259kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 54.6MB/s \n",
            "\u001b[?25hCollecting transformers<3.6,>=3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 51.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp) (3.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.6.0->allennlp) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.6.0->allennlp) (3.7.4.3)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.1MB/s \n",
            "\u001b[?25hCollecting botocore<1.20.0,>=1.19.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/f8/d355891fc244cb31ad8a30ce452efbf2b31a48da0239f220a871c54fe829/botocore-1.19.35-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 53.7MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (50.3.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (20.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (8.6.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp) (0.17.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (0.8.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (2.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (0.4.1)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 49.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.6,>=3.4->allennlp) (20.7)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 47.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.6,>=3.4->allennlp) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 52.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle->allennlp) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.35->boto3<2.0,>=1.14->allennlp) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.6,>=3.4->allennlp) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.6,>=3.4->allennlp) (7.1.2)\n",
            "Building wheels for collected packages: overrides, jsonnet, sacremoses\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp36-none-any.whl size=10175 sha256=cd1c8ab46e8345292e122a9d03ff839161b98029fdddcc1f4520a5eb4818fb4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.17.0-cp36-cp36m-linux_x86_64.whl size=3387940 sha256=99f7f79bdd622aae7cf31444c7bec801f82461aa0d2d835047e1af2063c4af9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/7a/37/7dbcc30a6b4efd17b91ad1f0128b7bbf84813bd4e1cfb8c1e3\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=dbb53a2122dee6aa2127d5d872cd637c66a6fa6dd4f36df0786ea37a5ae1f0fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built overrides jsonnet sacremoses\n",
            "\u001b[31mERROR: botocore 1.19.35 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: overrides, jsonpickle, jmespath, botocore, s3transfer, boto3, jsonnet, sentencepiece, tokenizers, sacremoses, transformers, allennlp\n",
            "Successfully installed allennlp-1.2.2 boto3-1.16.35 botocore-1.19.35 jmespath-0.10.0 jsonnet-0.17.0 jsonpickle-1.4.2 overrides-3.1.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GPe_Vj5fUYd",
        "outputId": "ea7a28f6-ec47-4bed-851c-bdcca001bebf"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Dec 11 20:31:56 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUKjfF4fgQPs",
        "outputId": "f47473cd-e5be-4bdf-e0c4-597571ca49e2"
      },
      "source": [
        "!ls drive/MyDrive/lmd_transformer/small"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "end_of_epoch_3-5471-4.817442893981934  latest  train  val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChU7fY2jfdH5",
        "outputId": "90f295b0-cd66-493b-b71f-6acb3fbc79ad"
      },
      "source": [
        "%%writefile ds_config.json\n",
        "\n",
        "{\n",
        "  \"train_batch_size\": 32,\n",
        "  \"gradient_accumulation_steps\": 8,\n",
        "  \"steps_per_print\": 20,\n",
        "  \"gradient_clipping\": 0.5,\n",
        "  \"optimizer\": {\n",
        "    \"type\": \"Adam\",\n",
        "    \"params\": {\n",
        "      \"lr\": 0.001,\n",
        "      \"betas\": [\n",
        "        0.9,\n",
        "        0.98\n",
        "      ],\n",
        "      \"eps\": 1e-8,\n",
        "      \"weight_decay\" : 0.1\n",
        "    }\n",
        "  },\n",
        "  \"amp\": {\n",
        "      \"enabled\": true,\n",
        "      \"opt_level\": \"O1\"\n",
        "  },\n",
        "  \"scheduler\": {\n",
        "    \"type\": \"WarmupLR\",\n",
        "    \"params\": {\n",
        "      \"warmup_min_lr\": 0,\n",
        "      \"warmup_max_lr\": 0.001,\n",
        "      \"warmup_num_steps\": 1000\n",
        "    }\n",
        "  }\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing ds_config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvcn21V2FFq5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54451866-5a68-4000-9b5e-07d2e3b2c360"
      },
      "source": [
        "%%writefile train_performer.py\n",
        "\n",
        "import deepspeed\n",
        "from performer_pytorch import PerformerEncDec\n",
        "import argparse\n",
        "import random\n",
        "import pandas as pd\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from allennlp.training.metrics import BLEU\n",
        "from itertools import cycle\n",
        "from pathlib import Path\n",
        "import os\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "\n",
        "\n",
        "def get_arguments():\n",
        "    parser=argparse.ArgumentParser(description='Lakh Midi Dataset Instruments-Vocals')\n",
        "\n",
        "    parser.add_argument('--dataset-file', '-df', type=str, required=True,\n",
        "                        help='Dataset parquet file')\n",
        "\n",
        "    parser.add_argument('--vocabulary-prefix', '-v', type=str, default='',\n",
        "                        help='Prefix of the vocab files: <pref>_instrumental.vocab, <prf>_vocal.vocab')\n",
        "\n",
        "    parser.add_argument('--save-dir', '-sd', type=str, required=True,\n",
        "                        help='Directory to save checkpoints, states, event logs')\n",
        "    \n",
        "    parser.add_argument('--monophonic', '-m', default=False, action='store_true',\n",
        "                        help='Use monophonic instead of full instrumental input')\n",
        "\n",
        "    parser.add_argument('--max-input-sequence-length', '-maxi', type=int, default=-1,\n",
        "                        help='If provided it will skip samples with longer input sequences')\n",
        "    \n",
        "    parser.add_argument('--max-output-sequence-length', '-maxo', type=int, default=-1,\n",
        "                        help='If provided it will skip samples with longer output sequences')\n",
        "    \n",
        "    parser.add_argument('--train-split', '-ts', type=float, default=0.9,\n",
        "                        help='Percentage of the dataset to use for training')\n",
        "\n",
        "    parser.add_argument('--epochs', '-e', type=int, default=20,\n",
        "                        help='Number of epochs')\n",
        "    \n",
        "    parser.add_argument('--validate-every', '-ve', type=int, default=200,\n",
        "                        help='Validate every n batches')\n",
        "    \n",
        "    parser.add_argument('--generate-every', '-ge', type=int, default=400,\n",
        "                        help='Generate every n batches')\n",
        "\n",
        "    parser.add_argument('--print-training-loss-every', '-ptle', type=int, default=20,\n",
        "                        help='It will average training loss and print it every n steps')\n",
        "\n",
        "    parser.add_argument('--validate-size', '-vs', type=int, default=40,\n",
        "                        help='Will calculate average of validation loss for n batches')\n",
        "\n",
        "    parser.add_argument('--validate-batch-size', '-vss', type=int, default=1,\n",
        "                        help='Batch size for validation dataset')\n",
        "\n",
        "    parser.add_argument('--checkpoints-per-epoch', '-cpp', type=int, default=3,\n",
        "                        help='How many checkpoints to keep per epoch')\n",
        "    \n",
        "    parser.add_argument('--local_rank', type=int, default=-1,\n",
        "                        help='Local rank passed from distributed launcher')\n",
        "    \n",
        "    parser = deepspeed.add_config_arguments(parser)\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "class MidiDataset(Dataset):\n",
        "    def __init__(self, dataset_file, monophonic, vocabulary_prefix, max_input_length, max_output_length):\n",
        "        super().__init__()\n",
        "        input_type = 'monophonic' if monophonic else 'instrumental'\n",
        "        with open('{}instrumental.vocab'.format(vocabulary_prefix), 'r') as f, \\\n",
        "            open('{}vocal.vocab'.format(vocabulary_prefix), 'r') as g: \n",
        "            self.input_vocab = {w : l for l, w in enumerate(f.read().splitlines())}\n",
        "            self.reverse_input_vocab = {l: w for w, l in self.input_vocab.items()}\n",
        "            self.output_vocab = {w : l for l, w in enumerate(g.read().splitlines())}\n",
        "            self.reverse_output_vocab = {l: w for w, l in self.output_vocab.items()}\n",
        "            \n",
        "        df = pd.read_parquet(dataset_file, columns=['vocal', input_type])\n",
        "        \n",
        "        inp = [self.encode(json.loads(f) + ['<eos>'], is_input=True) for f in df[input_type]]\n",
        "        out = [self.encode(['<bos>'] + json.loads(f) + ['<eos>'], is_input=False) for f in df['vocal']]\n",
        "\n",
        "        if max_input_length < 0 and max_output_length < 0:\n",
        "            self.input = inp\n",
        "            self.output = out\n",
        "        else:\n",
        "            self.input = []\n",
        "            self.output = []\n",
        "            for idx in range(len(inp)):\n",
        "                input_sample = inp[idx]\n",
        "                output_sample = out[idx]\n",
        "                if (max_input_length >= 0 and len(input_sample) > max_input_length) or \\\n",
        "                   (max_output_length >= 0 and len(output_sample) > max_output_length):\n",
        "                   continue\n",
        "                else:\n",
        "                    self.input.append(input_sample)\n",
        "                    self.output.append(output_sample)\n",
        "\n",
        "        self.max_input_length = max([len(f) for f in self.input])\n",
        "        self.max_output_length = max([len(f) for f in self.output])\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (self.input[index], self.output[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input)\n",
        "\n",
        "    def encode(self, event_sequence, is_input):\n",
        "        if is_input:\n",
        "            return torch.tensor([self.input_vocab[i] for i in event_sequence])\n",
        "        else:\n",
        "            return torch.tensor([self.output_vocab[i] for i in event_sequence])\n",
        "\n",
        "    def decode(self, event_sequence, is_input, mask=None):\n",
        "        size = len(event_sequence)\n",
        "        if mask is not None:\n",
        "            mask = mask.tolist()\n",
        "            true_size = len([v for v in mask if v])\n",
        "        else:\n",
        "            true_size = size\n",
        "        if is_input:\n",
        "            return \",\".join([self.reverse_input_vocab[i.item()] for i in event_sequence[:true_size]])\n",
        "        else:\n",
        "            return \",\".join([self.reverse_output_vocab[o.item()] for o in event_sequence[:true_size]])\n",
        "\n",
        "\n",
        "def collate_fn_zero_pad(batch):\n",
        "    inputs, outputs = zip(*batch)\n",
        "    batch_size = len(inputs)\n",
        "\n",
        "    if batch_size == 1:\n",
        "        inputs = inputs[0].view(1, -1)\n",
        "        outputs = outputs[0].view(1, -1)\n",
        "        input_masks = torch.ones_like(inputs).bool()\n",
        "        output_masks = torch.ones_like(outputs).bool()\n",
        "        return (inputs.long(), input_masks), (outputs.long(), output_masks)\n",
        "\n",
        "    input_lengths = [seq.size(0) for seq in inputs]\n",
        "    input_max_length = max(input_lengths)\n",
        "    input_masks = torch.arange(input_max_length).view(1, -1).expand(batch_size, -1) < torch.tensor(input_lengths).view(-1, 1)\n",
        "    padded_inputs = torch.zeros(batch_size, input_max_length)\n",
        "    for i, l in enumerate(input_lengths):\n",
        "        padded_inputs[i, :l] = inputs[i]\n",
        "\n",
        "    output_lengths = [seq.size(0) for seq in outputs]\n",
        "    output_max_length = max(output_lengths)\n",
        "    output_masks = torch.arange(output_max_length).view(1, -1).expand(batch_size, -1) < torch.tensor(output_lengths).view(-1, 1)\n",
        "    padded_outputs = torch.zeros(batch_size, output_max_length)\n",
        "    for i, l in enumerate(output_lengths):\n",
        "        padded_outputs[i, :l] = outputs[i]\n",
        "\n",
        "    return (padded_inputs.long(), input_masks), (padded_outputs.long(), output_masks)\n",
        "\n",
        "\n",
        "def valid_structure_metric(sequence, vocab_size):\n",
        "    def get_note(e, on):\n",
        "        if on:\n",
        "            e -= ons[0]\n",
        "            e %= 32\n",
        "        else:\n",
        "            e -= offs[0]\n",
        "        return e + 21\n",
        "\n",
        "    def set_valids_for_next(e):\n",
        "        if e == waits[-1]:\n",
        "            valid_events = waits + offs + syllables + ons\n",
        "        elif e in waits:\n",
        "            valid_events = offs + syllables + ons\n",
        "        elif e in ons:\n",
        "            last_note_on = get_note(e, on=True)\n",
        "            valid_events = waits\n",
        "        elif e in offs:\n",
        "            last_note_on = None\n",
        "            valid_events = waits + syllables + ons\n",
        "        else:\n",
        "            valid_events = ons\n",
        "\n",
        "    waits = list(range(3, 1003))\n",
        "    ons = list(range(1003, 3819))\n",
        "    offs = list(range(3819, 3907))\n",
        "    syllables = list(range(3907, vocab_size))\n",
        "    \n",
        "    valid_count = 0\n",
        "    valid_events = waits + syllables\n",
        "    last_note_on = None\n",
        "    for e in sequence:\n",
        "        if e in valid_events and \\\n",
        "        (e not in ons or last_note_on is None) and \\\n",
        "        (e not in offs or get_note(e, on=False) == last_note_on):\n",
        "            valid_count += 1\n",
        "        set_valids_for_next(e)\n",
        "\n",
        "    size = len(sequence) - 1 if sequence[-1] == 2 else len(sequence)\n",
        "    return valid_count / size\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args = get_arguments()\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    dataset = MidiDataset(dataset_file=args.dataset_file,\n",
        "                          monophonic=args.monophonic,\n",
        "                          vocabulary_prefix=args.vocabulary_prefix,\n",
        "                          max_input_length=args.max_input_sequence_length,\n",
        "                          max_output_length=args.max_output_sequence_length)\n",
        "\n",
        "    train_size = int(args.train_split * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    \n",
        "    torch.manual_seed(0)\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    train_log_dir = os.path.join(args.save_dir, 'train')\n",
        "    val_log_dir = os.path.join(args.save_dir, 'val')\n",
        "    Path(train_log_dir).mkdir(parents=True, exist_ok=True)\n",
        "    Path(val_log_dir).mkdir(parents=True, exist_ok=True)\n",
        "    writer_train = SummaryWriter(log_dir=train_log_dir)\n",
        "    writer_val = SummaryWriter(log_dir=val_log_dir)\n",
        "    \n",
        "    bleu = BLEU()\n",
        "\n",
        "    model = PerformerEncDec(\n",
        "        dim = 512,\n",
        "        enc_heads = 8,\n",
        "        dec_heads = 8,\n",
        "        enc_depth = 6,\n",
        "        dec_depth = 6,\n",
        "        enc_ff_chunks = 10,\n",
        "        dec_ff_chunks = 10,\n",
        "        enc_num_tokens = len(dataset.input_vocab),\n",
        "        dec_num_tokens = len(dataset.output_vocab),\n",
        "        enc_max_seq_len = dataset.max_input_length,\n",
        "        dec_max_seq_len = dataset.max_output_length,\n",
        "        ignore_index = 0,\n",
        "        pad_value = 0,\n",
        "        enc_emb_dropout = 0.1,\n",
        "        dec_emb_dropout = 0.1,\n",
        "        enc_ff_dropout = 0.1,\n",
        "        dec_ff_dropout = 0.1,\n",
        "        enc_attn_dropout = 0.1,\n",
        "        dec_attn_dropout = 0.1,\n",
        "        enc_reversible = True,\n",
        "        dec_reversible = True,\n",
        "        enc_amp_enabled = True,\n",
        "        dec_amp_enabled = True\n",
        "    ).to(device)\n",
        "\n",
        "    model_engine, optimizer, trainloader, _ = deepspeed.initialize(args=args, model=model, model_parameters=model.parameters(),  training_data=train_dataset, collate_fn=collate_fn_zero_pad)\n",
        "    device = model_engine.local_rank\n",
        "\n",
        "    torch.manual_seed(torch.initial_seed())\n",
        "    val_loader_ = DataLoader(val_dataset, batch_size=args.validate_batch_size, shuffle=True, collate_fn=collate_fn_zero_pad)\n",
        "    val_loader = cycle(val_loader_)\n",
        "\n",
        "    num_batches = (len(train_dataset) + trainloader.batch_size - 1) // trainloader.batch_size\n",
        "\n",
        "    save_every = num_batches // args.checkpoints_per_epoch\n",
        "    save_at = 0\n",
        "    saving_steps = []\n",
        "    for _ in range(args.checkpoints_per_epoch - 1):\n",
        "        save_at += save_every\n",
        "        saving_steps.append(save_at)\n",
        "    saving_steps.append(num_batches - 1)\n",
        "\n",
        "    print(\"\\n\", \"Dataset maximum sequence lengths - Input: {}, Output: {}\".format(dataset.max_input_length, dataset.max_output_length), \"\\n\")\n",
        "    print(\"\\n\", \"Train Dataset - size: {}, batches: {}\".format(len(train_dataset), num_batches), \"\\n\")\n",
        "    print(\"\\n\", \"Validate Dataset - size: {}, batches: {}\".format(len(val_dataset), len(val_loader_)), \"\\n\")\n",
        "\n",
        "    checkpoint_name, client_state = model_engine.load_checkpoint(args.save_dir, load_module_strict=False)\n",
        "\n",
        "    if checkpoint_name is not None:\n",
        "        print(\"\\nLoaded checkpoint: {}\\n\".format(checkpoint_name))        \n",
        "        i = client_state['i']\n",
        "        i += 1\n",
        "        epoch, step = divmod(i, num_batches)\n",
        "        if 'step' in client_state:\n",
        "            assert step == client_state['step']\n",
        "        if 'epoch' in client_state:\n",
        "            assert epoch == client_state['epoch']\n",
        "        print(\"Epoch: {}, step: {}, i: {}\".format(epoch, step, i))\n",
        "        if step == 0:\n",
        "            print(\"Starting next epoch...\")\n",
        "            rng = torch.get_rng_state()\n",
        "            trainloader = iter(trainloader)\n",
        "        else:\n",
        "            rng = torch.load(os.path.join(args.save_dir, 'rng_state.pt'))\n",
        "            torch.set_rng_state(rng)\n",
        "            trainloader = iter(trainloader)\n",
        "            print(\"Advancing dataloader...\")\n",
        "            for _ in tqdm(range(step)):\n",
        "                next(trainloader)\n",
        "    else:\n",
        "        print(\"\\nNo checkpoint found, training from scratch\\n\")\n",
        "        i = 0\n",
        "        step = 0\n",
        "        epoch = 0\n",
        "        rng = torch.get_rng_state()\n",
        "        trainloader = iter(trainloader)\n",
        "\n",
        "\n",
        "    for e in range(args.epochs - epoch):\n",
        "        running_loss = 0\n",
        "        running_loss_steps = 0\n",
        "        print(\"EPOCH: {}\".format(e + epoch))\n",
        "        while True:\n",
        "            try:\n",
        "                data = next(trainloader)\n",
        "            except StopIteration:\n",
        "                step = 0\n",
        "                rng = torch.get_rng_state()\n",
        "                trainloader = iter(trainloader)\n",
        "                break\n",
        "\n",
        "            model_engine.train()\n",
        "            (inp, inp_mask), (out, out_mask) = data\n",
        "            loss = model_engine(inp.to(device), out.to(device), enc_mask=inp_mask.to(device), dec_mask=out_mask.to(device), return_loss=True)\n",
        "            model_engine.backward(loss)\n",
        "            model_engine.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            running_loss_steps += 1\n",
        "            if running_loss_steps == args.print_training_loss_every or step == 0:\n",
        "                avg_loss = running_loss / running_loss_steps\n",
        "                print(\"training loss: {}\".format(avg_loss))\n",
        "                writer_train.add_scalar(\"Loss\", avg_loss, i)\n",
        "                writer_train.flush()\n",
        "                running_loss = 0\n",
        "                running_loss_steps = 0\n",
        "\n",
        "            if step % args.validate_every == 0:\n",
        "                model_engine.eval()\n",
        "                with torch.no_grad():\n",
        "                    running_eval_loss = 0\n",
        "                    for _ in range(args.validate_size):\n",
        "                        (inp, inp_mask), (out, out_mask) = next(val_loader)\n",
        "                        loss = model_engine(inp.to(device), out.to(device), return_loss=True, enc_mask=inp_mask.to(device), dec_mask=out_mask.to(device))\n",
        "                        running_eval_loss += loss.item()\n",
        "                    avg_eval_loss = running_eval_loss / args.validate_size\n",
        "                    print('\\n', f'validation loss: {avg_eval_loss}', '\\n')\n",
        "                    writer_val.add_scalar(\"Loss\", avg_eval_loss, i)\n",
        "                    writer_val.flush()\n",
        "                    running_eval_loss = 0\n",
        "\n",
        "            if step % args.generate_every == 0:\n",
        "                (inp, inp_mask), (expected_out, expected_out_mask) = next(val_loader)\n",
        "                print(dataset.decode(inp[0], is_input=True, mask=inp_mask[0]))\n",
        "                print(dataset.decode(expected_out[0][1:], is_input=False, mask=expected_out_mask[0][1:]))\n",
        "\n",
        "                inp = inp[0].view(1, -1)\n",
        "                inp_mask = inp_mask[0].view(1, -1)\n",
        "                \n",
        "                # <bos> token\n",
        "                initial = torch.ones(1,1).long()\n",
        "\n",
        "                out = model_engine.module.generate(inp.to(device), initial.to(device), enc_mask=inp_mask.to(device), seq_len=len(expected_out[0]) - 2, eos_token=2)\n",
        "                print(dataset.decode(out[0], is_input=False))\n",
        "                \n",
        "                bleu(out.to(device), expected_out[:, 1:].to(device))\n",
        "                b = bleu.get_metric(reset=True)['BLEU']\n",
        "                vsm = valid_structure_metric(out[0], len(dataset.output_vocab))\n",
        "                expected_vsm = valid_structure_metric(expected_out[0][1:], len(dataset.output_vocab))\n",
        "\n",
        "                print(\"BLEU metric: {}\".format(b))\n",
        "                print(\"Valid Structure Metric: {}\".format(vsm))\n",
        "                print(\"Expected Valid Structure Metric: {} (for control)\".format(expected_vsm))\n",
        "                writer_val.add_scalar(\"BLEU\", b, i)\n",
        "                writer_val.add_scalar(\"VSM\", vsm, i)\n",
        "                writer_val.flush()\n",
        "\n",
        "            if step in saving_steps:\n",
        "                loss_to_ckpt = avg_eval_loss if avg_eval_loss is not None else loss.item()\n",
        "                ckpt_id = \"{}-{}-{}\".format(e + epoch, i, loss_to_ckpt)\n",
        "                model_engine.save_checkpoint(args.save_dir, tag=ckpt_id, client_state = {'i': i, 'step': step, 'epoch': e + epoch})\n",
        "                torch.save(rng, os.path.join(args.save_dir, 'rng_state.pt'))\n",
        "\n",
        "            i += 1\n",
        "            step += 1\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting train_performer.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbQEF6i8kD0h"
      },
      "source": [
        "!deepspeed train_performer.py -df drive/MyDrive/lmd_transformer/small_dataset.parquet -v drive/MyDrive/lmd_transformer/small_ -sd drive/MyDrive/lmd_transformer/small --deepspeed --deepspeed_config ds_config.json"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}